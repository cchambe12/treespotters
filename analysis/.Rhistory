d <- within(d, forcetemp[datasetID == 'man10' & response.time.num == 28 & response == 100] <- 22)
d <- within(d, forcetemp[datasetID == 'man10' & response.time.num == 18 & response == 0] <- 16)
d <- within(d, forcetemp[datasetID == 'man10' & response.time.num == 19 & response == 20.981] <- 16)
d <- within(d, forcetemp[datasetID == 'man10' & response.time.num == 20 & response == 45.231] <- 16)
d <- within(d, forcetemp[datasetID == 'man10' & response.time.num == 21 & response == 75.684] <- 19)
d <- within(d, forcetemp[datasetID == 'man10' & response.time.num == 22 & response == 90.156] <- 19)
d <- within(d, forcetemp[datasetID == 'man10' & response.time.num == 23 & response == 97.813] <- 19)
d <- within(d, forcetemp[datasetID == 'man10' & response.time.num == 24 & response == 97.813] <- 19)
d <- within(d, forcetemp[datasetID == 'man10' & response.time.num == 25 & response == 98.167] <- 19)
d <- within(d, forcetemp[datasetID == 'man10' & response.time.num == 26 & response == 99.267] <- 19)
d <- within(d, forcetemp[datasetID == 'man10' & response.time.num == 27 & response == 100] <- 19)
# schnabel87 - fix 10 for 2 week, then... to 10
d <- within(d, forcetemp[datasetID == 'schnabel87' & n == 30 & response.time.num == 35.4] <- 10)
# campbell75 - fix from 18-27 (20 average) to 20
d <- within(d, forcetemp[datasetID == 'campbell75' & study== "exp1"] <- 20)
# howe95 - calculated mean, changed from 22-27 to 24.5
d <- within(d, forcetemp[datasetID == 'howe95'] <- 24.5)
# laube14a
d.sub$response.time<- as.numeric(d.sub$response.time)
for(i in c(1:nrow(d.sub))) {
for(j in c(1:nrow(laube14)))
d.sub$forcetemp[i]<-ifelse(d.sub$response.time[i] == laube14$day[j], laube14$temp[j], d.sub$forcetemp[i])
}
d.sub$forcetemp<-ifelse(is.na(d.sub$response.time), 27.5, d.sub$forcetemp)
d.sub$response.time<-ifelse(is.na(d.sub$response.time), "no response", d.sub$response.time)
d$forcetemp[which(d$datasetID=="laube14a")]<-d.sub$forcetemp
# skuterud94 now - is thermal time, does not explicitly say which forcing temp
# for each tx (mean 9, 12, 15)
# basler12 - "Temperature was set to cycle Â±5 K around the daily mean temperature, which was increased by
# 0.5 K every five days"
## Fixed 13 Apr 2018 - Cat
d$forcetemp<-ifelse(d$datasetID=="basler12" & d$respvar.simple=="daystobudburst" & d$response.time.num>=0 & d$response.time.num<5, 5, d$forcetemp)
d$forcetemp<-ifelse(d$datasetID=="basler12" & d$respvar.simple=="daystobudburst" & d$response.time.num>=5 & d$response.time.num<10, 5.5, d$forcetemp)
d$forcetemp<-ifelse(d$datasetID=="basler12" & d$respvar.simple=="daystobudburst" & d$response.time.num>=10 & d$response.time.num<15, 6, d$forcetemp)
d$forcetemp<-ifelse(d$datasetID=="basler12" & d$respvar.simple=="daystobudburst" & d$response.time.num>=15 & d$response.time.num<20, 6.5, d$forcetemp)
d$forcetemp<-ifelse(d$datasetID=="basler12" & d$respvar.simple=="daystobudburst" & d$response.time.num>=20 & d$response.time.num<25, 7, d$forcetemp)
d$forcetemp<-ifelse(d$datasetID=="basler12" & d$respvar.simple=="daystobudburst" & d$response.time.num>=25 & d$response.time.num<30, 7.5, d$forcetemp)
d$forcetemp<-ifelse(d$datasetID=="basler12" & d$respvar.simple=="daystobudburst" & d$response.time.num>=30 & d$response.time.num<35, 8, d$forcetemp)
d$forcetemp<-ifelse(d$datasetID=="basler12" & d$respvar.simple=="daystobudburst" & d$response.time.num>=35 & d$response.time.num<40, 8.5, d$forcetemp)
d$forcetemp<-ifelse(d$datasetID=="basler12" & d$respvar.simple=="daystobudburst" & d$response.time.num>=40 & d$response.time.num<45, 9, d$forcetemp)
d$forcetemp<-ifelse(d$datasetID=="basler12" & d$respvar.simple=="daystobudburst" & d$response.time.num>=45 & d$response.time.num<50, 9.5, d$forcetemp)
d$forcetemp<-ifelse(d$datasetID=="basler12" & d$respvar.simple=="daystobudburst" & d$response.time.num>=50 & d$response.time.num<55, 10, d$forcetemp)
d$forcetemp<-ifelse(d$datasetID=="basler12" & d$respvar.simple=="daystobudburst" & d$response.time.num>=55 & d$response.time.num<60, 10.5, d$forcetemp)
d$forcetemp<-ifelse(d$datasetID=="basler12" & d$respvar.simple=="daystobudburst" & d$response.time.num>=60 & d$response.time.num<65, 11, d$forcetemp)
d$forcetemp<-ifelse(d$datasetID=="basler12" & d$respvar.simple=="daystobudburst" & d$response.time.num>=65 & d$response.time.num<70, 11.5, d$forcetemp)
# guak98: does not specify the "ambient" temperature but increased by 4
# in other experiments, didn't change anything
# gunderson12: treatments were in relation to "thermal provenance" so I left them at ambient +2, +4
# delete the new response.time column that we don't need!
d$response.time.num <- NULL
rm(list=ls())
options(stringsAsFactors = FALSE)
# Set working directory:
if(length(grep("Lizzie", getwd())>0)) { setwd("~/Documents/git/projects/treegarden/budreview/ospree/analyses")
} else if
(length(grep("Ignacio", getwd()))>0) { setwd("~/GitHub/ospree/analyses")
} else if
(length(grep("ailene", getwd()))>0) {setwd("/Users/aileneettinger/git/ospree/analyses")
} else
setwd("~/Documents/git/ospree/analyses")
# Load libraries
library(dplyr)
library(tidyr)
library(geosphere)
library(lubridate)
# 1. Get the data (that has already been cleaned for respvar and chilling)
d <- read.csv("output/ospree_clean_withchill.csv") # 29 May 2018: 12693
# 2. Need to deal with thermal time to days
source("bb_analysis/cleaning/clean_thermaltimetodays.R") # 29 May 2018: 12693
# 3. Clean phenstage to get a little more data (a little, but still!).
source("bb_analysis/cleaning/clean_respvarmore.R") # 29 May 2018: 12152
# 4. Select out the highest percentage of budburst only, and remove studies that contain duplicate data in two forms
source("bb_analysis/cleaning/multiresp.R") # as of 16 July 2017, deletes ~2400 rows (same in May 2018) 9717 rows
# 5. Clean ambient forcing
amb<-d[which(d$forcetemp=="ambient"),]
unique(amb$datasetID)
### "boyer"       "cannell83"   "falusi96"    "fu13"        "guak98"      "gunderson12" "lamb37"
### "morin10"     "sanzperez10" "sonsteby13"
blank<- d[which(d$forcetemp==""),]
nas<-d[which(is.na(d$forcetemp)),]
unique(nas$datasetID)
unique(blank$datasetID)
d$response.time.num <-as.numeric(as.character(d$response.time))
## "ashby62"  "gansert02"  "hawkins12"  "ruesink98"
# ashby62: not enough information - above 3 degC but not sure how much more
# gansert02: ambient, maybe we can use climate data to calculate - imputed to be 5degC based on Fig 5
## Fixed 6 Feb 2018 - Cat
#d$forcetemp[which(d$datasetID=="gansert02")] <- 5
# hawkins12: complicated thermal time equation - maybe use climate data instead?
# ruesink98: flower data... not sure how it got through
# boyer: not enough information - assumed ambient, maybe could use climate data to calculate
# cannell83: ambient - maybe could use climate data to calculate
# falusi96: not enough information - assumed ambient, maybe could use climate data to calculate
## Calculates GDDs based on 5degC base temp. I will change to 5degC for now. To discuss.
## Fixed 6 Feb 2018 - Cat
#d$forcetemp[which(d$datasetID=="falusi96" & d$study=="exp1")] <- 5
# fu13: uses ambient temperature and some add degrees C, maybe could use climate data to calculate
# guak98: uses ambient temperature and some add degrees C, maybe could use climate data to calculate
## rough estimate based on Fig1
## Fixed 6 Feb 2018 - Cat
#d$forcetemp[which(d$datasetID=="guak98" & d$forcetemp=="ambient")] <- 12
#d$forcetemp[which(d$datasetID=="guak98" & d$forcetemp=="ambient + 4")] <- 16
# gunderson12: uses ambient temperature and some add degrees C, maybe could use climate data to calculate
# lamb37: not enough information - assumes ambient, maybe could use climate data to calculate
# morin10: uses ambient temperature and some add degrees C, maybe could use climate data to calculate
## Used rough estimate based on Fig1 - ambient = 15 -> 16.5 and 18
## Fixed 6 Feb 2018 - Cat
#d$forcetemp[which(d$datasetID=="morin10" & d$forcetemp=="ambient")] <- 15
#d$forcetemp[which(d$datasetID=="morin10" & d$forcetemp=="ambient + 1.5")] <- 16.5
#d$forcetemp[which(d$datasetID=="morin10" & d$forcetemp=="ambient + 3")] <- 18
# sanperez10: uses ambient temperature, recorded mean temperature per month - can extract data from there
#d$forcetemp[which(d$datasetID=="sanzperez10" & d$response.time.num>=0 & d$response.time.num<=30
#                 & d$irradiance==100)] <- 6.2
#d$forcetemp[which(d$datasetID=="sanzperez10" & d$response.time.num>=0 & d$response.time.num<=30
#                 & d$irradiance==20)] <- 5.2
#d$forcetemp[which(d$datasetID=="sanzperez10" & d$response.time.num>=0 & d$response.time.num<=30
#                 & d$irradiance==5)] <- 5.4
#d$forcetemp[which(d$datasetID=="sanzperez10" & d$response.time.num>=31 & d$response.time.num<=59
#                 & d$irradiance==100)] <- 6.4
#d$forcetemp[which(d$datasetID=="sanzperez10" & d$response.time.num>=31 & d$response.time.num<=59
#                 & d$irradiance==20)] <- 4.8
#d$forcetemp[which(d$datasetID=="sanzperez10" & d$response.time.num>=31 & d$response.time.num<=59
#                 & d$irradiance==5)] <- 5.2
#d$forcetemp[which(d$datasetID=="sanzperez10" & d$response.time.num>=60 & d$response.time.num<=90
#                & d$irradiance==100)] <- 8.9
#d$forcetemp[which(d$datasetID=="sanzperez10" & d$response.time.num>=60 & d$response.time.num<=90
#                 & d$irradiance==20)] <- 7.1
#d$forcetemp[which(d$datasetID=="sanzperez10" & d$response.time.num>=60 & d$response.time.num<=90
#                 & d$irradiance==5)] <- 7.5
#d$forcetemp[which(d$datasetID=="sanzperez10" & d$response.time.num>=91 & d$response.time.num<=120
#                 & d$irradiance==100)] <- 10.7
#d$forcetemp[which(d$datasetID=="sanzperez10" & d$response.time.num>=91 & d$response.time.num<=120
#                 & d$irradiance==20)] <- 9.2
#d$forcetemp[which(d$datasetID=="sanzperez10" & d$response.time.num>=91 & d$response.time.num<=120
#                 & d$irradiance==5)] <- 9.7
# sonsteby13: flower bud study... not sure why it made it through
# man10 - fix from 0 ramped up 3 degrees every 6 days
d <- within(d, forcetemp[datasetID == 'man10' & response.time.num == 28 & response == 100] <- 22)
d <- within(d, forcetemp[datasetID == 'man10' & response.time.num == 18 & response == 0] <- 16)
d <- within(d, forcetemp[datasetID == 'man10' & response.time.num == 19 & response == 20.981] <- 16)
d <- within(d, forcetemp[datasetID == 'man10' & response.time.num == 20 & response == 45.231] <- 16)
d <- within(d, forcetemp[datasetID == 'man10' & response.time.num == 21 & response == 75.684] <- 19)
d <- within(d, forcetemp[datasetID == 'man10' & response.time.num == 22 & response == 90.156] <- 19)
d <- within(d, forcetemp[datasetID == 'man10' & response.time.num == 23 & response == 97.813] <- 19)
d <- within(d, forcetemp[datasetID == 'man10' & response.time.num == 24 & response == 97.813] <- 19)
d <- within(d, forcetemp[datasetID == 'man10' & response.time.num == 25 & response == 98.167] <- 19)
d <- within(d, forcetemp[datasetID == 'man10' & response.time.num == 26 & response == 99.267] <- 19)
d <- within(d, forcetemp[datasetID == 'man10' & response.time.num == 27 & response == 100] <- 19)
# schnabel87 - fix 10 for 2 week, then... to 10
d <- within(d, forcetemp[datasetID == 'schnabel87' & n == 30 & response.time.num == 35.4] <- 10)
# campbell75 - fix from 18-27 (20 average) to 20
d <- within(d, forcetemp[datasetID == 'campbell75' & study== "exp1"] <- 20)
# howe95 - calculated mean, changed from 22-27 to 24.5
d <- within(d, forcetemp[datasetID == 'howe95'] <- 24.5)
# laube14a
d.sub$response.time<- as.numeric(d.sub$response.time)
for(i in c(1:nrow(d.sub))) {
for(j in c(1:nrow(laube14)))
d.sub$forcetemp[i]<-ifelse(d.sub$response.time[i] == laube14$day[j], laube14$temp[j], d.sub$forcetemp[i])
}
d.sub$forcetemp<-ifelse(is.na(d.sub$response.time), 27.5, d.sub$forcetemp)
d.sub$response.time<-ifelse(is.na(d.sub$response.time), "no response", d.sub$response.time)
d$forcetemp[which(d$datasetID=="laube14a")]<-d.sub$forcetemp
# skuterud94 now - is thermal time, does not explicitly say which forcing temp
# for each tx (mean 9, 12, 15)
# basler12 - "Temperature was set to cycle Â±5 K around the daily mean temperature, which was increased by
# 0.5 K every five days"
## Fixed 13 Apr 2018 - Cat
d$forcetemp<-ifelse(d$datasetID=="basler12" & d$respvar.simple=="daystobudburst" & d$response.time.num>=0 & d$response.time.num<5, 5, d$forcetemp)
d$forcetemp<-ifelse(d$datasetID=="basler12" & d$respvar.simple=="daystobudburst" & d$response.time.num>=5 & d$response.time.num<10, 5.5, d$forcetemp)
d$forcetemp<-ifelse(d$datasetID=="basler12" & d$respvar.simple=="daystobudburst" & d$response.time.num>=10 & d$response.time.num<15, 6, d$forcetemp)
d$forcetemp<-ifelse(d$datasetID=="basler12" & d$respvar.simple=="daystobudburst" & d$response.time.num>=15 & d$response.time.num<20, 6.5, d$forcetemp)
d$forcetemp<-ifelse(d$datasetID=="basler12" & d$respvar.simple=="daystobudburst" & d$response.time.num>=20 & d$response.time.num<25, 7, d$forcetemp)
d$forcetemp<-ifelse(d$datasetID=="basler12" & d$respvar.simple=="daystobudburst" & d$response.time.num>=25 & d$response.time.num<30, 7.5, d$forcetemp)
d$forcetemp<-ifelse(d$datasetID=="basler12" & d$respvar.simple=="daystobudburst" & d$response.time.num>=30 & d$response.time.num<35, 8, d$forcetemp)
d$forcetemp<-ifelse(d$datasetID=="basler12" & d$respvar.simple=="daystobudburst" & d$response.time.num>=35 & d$response.time.num<40, 8.5, d$forcetemp)
d$forcetemp<-ifelse(d$datasetID=="basler12" & d$respvar.simple=="daystobudburst" & d$response.time.num>=40 & d$response.time.num<45, 9, d$forcetemp)
d$forcetemp<-ifelse(d$datasetID=="basler12" & d$respvar.simple=="daystobudburst" & d$response.time.num>=45 & d$response.time.num<50, 9.5, d$forcetemp)
d$forcetemp<-ifelse(d$datasetID=="basler12" & d$respvar.simple=="daystobudburst" & d$response.time.num>=50 & d$response.time.num<55, 10, d$forcetemp)
d$forcetemp<-ifelse(d$datasetID=="basler12" & d$respvar.simple=="daystobudburst" & d$response.time.num>=55 & d$response.time.num<60, 10.5, d$forcetemp)
d$forcetemp<-ifelse(d$datasetID=="basler12" & d$respvar.simple=="daystobudburst" & d$response.time.num>=60 & d$response.time.num<65, 11, d$forcetemp)
d$forcetemp<-ifelse(d$datasetID=="basler12" & d$respvar.simple=="daystobudburst" & d$response.time.num>=65 & d$response.time.num<70, 11.5, d$forcetemp)
# guak98: does not specify the "ambient" temperature but increased by 4
# in other experiments, didn't change anything
# gunderson12: treatments were in relation to "thermal provenance" so I left them at ambient +2, +4
# delete the new response.time column that we don't need!
d$response.time.num <- NULL
check<-as.data.frame(as.numeric(d$forcetemp))
check<-as.data.frame(table(d$forcetemp))
View(check)
View(d)
foo<-d[(d$datasetID=="basler12" | d$datasetID=="laube14a" | d$datasetID=="man10"),]
rm(list=ls())
options(stringsAsFactors = FALSE)
# Set working directory:
if(length(grep("Lizzie", getwd())>0)) { setwd("~/Documents/git/projects/treegarden/budreview/ospree/analyses")
} else if
(length(grep("Ignacio", getwd()))>0) { setwd("~/GitHub/ospree/analyses")
} else if
(length(grep("ailene", getwd()))>0) {setwd("/Users/aileneettinger/git/ospree/analyses")
} else
setwd("~/Documents/git/ospree/analyses")
# Load libraries
library(dplyr)
library(tidyr)
library(geosphere)
library(lubridate)
# 1. Get the data (that has already been cleaned for respvar and chilling)
d <- read.csv("output/ospree_clean_withchill.csv") # 29 May 2018: 12693
# 2. Need to deal with thermal time to days
source("bb_analysis/cleaning/clean_thermaltimetodays.R") # 29 May 2018: 12693
# 3. Clean phenstage to get a little more data (a little, but still!).
source("bb_analysis/cleaning/clean_respvarmore.R") # 29 May 2018: 12152
# 4. Select out the highest percentage of budburst only, and remove studies that contain duplicate data in two forms
source("bb_analysis/cleaning/multiresp.R") # as of 16 July 2017, deletes ~2400 rows (same in May 2018) 9717 rows
# 5. Clean ambient forcing
# 5a. Clean up entries where we can estimate the forcing from the paper (e.g., ramped temps or they give monthly temps)
source("bb_analysis/cleaning/clean_ambientforcing.R")
table(d$force_type)
rm(list=ls())
options(stringsAsFactors = FALSE)
# Set working directory:
if(length(grep("Lizzie", getwd())>0)) { setwd("~/Documents/git/projects/treegarden/budreview/ospree/analyses")
} else if
(length(grep("Ignacio", getwd()))>0) { setwd("~/GitHub/ospree/analyses")
} else if
(length(grep("ailene", getwd()))>0) {setwd("/Users/aileneettinger/git/ospree/analyses")
} else
setwd("~/Documents/git/ospree/analyses")
# Load libraries
library(dplyr)
library(tidyr)
library(geosphere)
library(lubridate)
# 1. Get the data (that has already been cleaned for respvar and chilling)
d <- read.csv("output/ospree_clean_withchill.csv") # 29 May 2018: 12693
# 2. Need to deal with thermal time to days
source("bb_analysis/cleaning/clean_thermaltimetodays.R") # 29 May 2018: 12693
# 3. Clean phenstage to get a little more data (a little, but still!).
source("bb_analysis/cleaning/clean_respvarmore.R") # 29 May 2018: 12152
# 4. Select out the highest percentage of budburst only, and remove studies that contain duplicate data in two forms
source("bb_analysis/cleaning/multiresp.R") # as of 16 July 2017, deletes ~2400 rows (same in May 2018) 9717 rows
# 5. Clean ambient forcing
# 5a. Clean up entries where we can estimate the forcing from the paper (e.g., ramped temps or they give monthly temps)
source("bb_analysis/cleaning/clean_ambientforcing.R")
table(d$force_type)
View(d)
rm(list=ls())
options(stringsAsFactors = FALSE)
# Set working directory:
if(length(grep("Lizzie", getwd())>0)) { setwd("~/Documents/git/projects/treegarden/budreview/ospree/analyses")
} else if
(length(grep("Ignacio", getwd()))>0) { setwd("~/GitHub/ospree/analyses")
} else if
(length(grep("ailene", getwd()))>0) {setwd("/Users/aileneettinger/git/ospree/analyses")
} else
setwd("~/Documents/git/ospree/analyses")
# Load libraries
library(dplyr)
library(tidyr)
library(geosphere)
library(lubridate)
# 1. Get the data (that has already been cleaned for respvar and chilling)
d <- read.csv("output/ospree_clean_withchill.csv") # 29 May 2018: 12693
# 2. Need to deal with thermal time to days
source("bb_analysis/cleaning/clean_thermaltimetodays.R") # 29 May 2018: 12693
# 3. Clean phenstage to get a little more data (a little, but still!).
source("bb_analysis/cleaning/clean_respvarmore.R") # 29 May 2018: 12152
# 4. Select out the highest percentage of budburst only, and remove studies that contain duplicate data in two forms
source("bb_analysis/cleaning/multiresp.R") # as of 16 July 2017, deletes ~2400 rows (same in May 2018) 9717 rows
# 5. Clean ambient forcing
# 5a. Clean up entries where we can estimate the forcing from the paper (e.g., ramped temps or they give monthly temps)
source("bb_analysis/cleaning/clean_ambientforcing.R")
table(d$force_type)
unique(d$other.treatment)
goober<-d[(d$other.treatment)]
goober<-d[(d$other.treatment=="temperature ramping"),]
View(goober)
# 5b. Check date of daily climate files used in step 5c-
#if they are too old for your taste,run pulldailyclim.R and bb_daily_dataprep.R scripts (these take a while)
source("bb_analysis/cleaning/clean_checkdateofclimatedata.R") # As of 29 May 2018: 9717 rows
chill.day <- read.csv("output/dailyclim/daily_expchill.csv")
chill.unique.exptreat<-unique(chill.day$uniqueID)
chillneeded <- subset(chill.day, select=c("uniqueID", "lastchilldate"))
chilly <- chillneeded[!duplicated(chillneeded), ]
#dim(chilly)
## read in data containing climate each day each site (it's big so it is in pieces)
#check the date of when these daily climate summary files were created in case they are older than you'd like:
#file.info("output/dailyclim/percbb_dailyclimA.csv")$ctime
#file.info("output/dailyclim/percbb_dailyclimB.csv")$ctime
#file.info("output/dailyclim/percbb_dailyclimC.csv")$ctime
#file.info("output/dailyclim/percbb_dailyclimD.csv")$ctime
#If those dates are deemed too old by you, then you should rerun
#'pulldailyclim.R' and 'bb_daily_dataprep.R' script (these scripts are slow).
clima <- read.csv("output/dailyclim/percbb_dailyclimA.csv", header=TRUE)
climb <- read.csv("output/dailyclim/percbb_dailyclimB.csv", header=TRUE)
climc <- read.csv("output/dailyclim/percbb_dailyclimC.csv", header=TRUE)
climd <- read.csv("output/dailyclim/percbb_dailyclimD.csv", header=TRUE)
climdatab <- rbind(clima,climb,climc,climd)
#dim(climdatab)#3331203
climdatab<-climdatab[-which(is.na(climdatab$Tmean)),]#Ailene added for now
#to remove climate data with NAs (need to fix dailyclim file)
#on 25 april 2018: there are 43 unique ids with NA climate data (from 7 studies)
climdat <- climdatab[!duplicated(climdatab), ]#559231 rows...why so much smaller?
#not sure why there are duplicates- duplicates were removed at the end of the bb_daily_dataprep.R code
rm(clima,climb,climc,climd)
## get all the BB data and format a little
#dat.all <- read.csv("output/ospree_clean_withchill.csv", header=TRUE)
dat.all<-d
dat.some <- subset(dat.all, respvar.simple=="daystobudburst"|respvar.simple=="percentbudburst")
bbdat <- subset(dat.some, response.time!="")
# format: make a column to match to climate data, and merge the BB and climate data
bbdat$uniqueID <- paste(bbdat$datasetID, bbdat$fieldsample.date2, bbdat$forcetemp, bbdat$chilltemp,
bbdat$chilldays,bbdat$chillphotoperiod, bbdat$photoperiod_day)
bb <- merge(chilly, bbdat, by="uniqueID", all.y=TRUE)
## add a column for when the experiment starts to bb data
# fill it in with either last date of experimental chilling or (if not present) field sample date
bb$expstartdate <- bb$lastchilldate # subset(bb, is.na(bb$expstartdate)==FALSE)
bb$expstartdate[which(is.na(bb$expstartdate)==TRUE)] <- bb$fieldsample.date2[which(is.na(bb$expstartdate)==TRUE)]
#dim(subset(bb, is.na(bb$expstartdate)==TRUE))
## okay, need to get response.time and expstartdate into date formats...
bb$expstartdate <- as.Date(bb$expstartdate, format="%Y-%m-%d")
bb$response.time.integer <- as.integer(bb$response.time)
bb$bbdate <- as.Date(bb$response.time.integer, origin=bb$expstartdate, format="%Y-%m-%d")
bb<-bb[-which(is.na(bb$response.time.integer)),]#Ailene added to get rid if response.time==NA
# generate an empty variable to store mean temps
bb$avg_bbtemp<-NA
missingclim<-NA#keep track of how many uniqueIDs are missing climate
## Loop to add mean temp to each line in bb
for(i in 1:nrow(bb)){#i=1832; nrow=5965 #2804 (jones12): missing climate data for first part- not sure why!
lon.i<-bb[i,"chill.long"]
lat.i<-bb[i,"chill.lat"]
start.i<-bb[i,"expstartdate"]
end.i<-bb[i,"bbdate"]
year.i<-as.numeric(format(start.i,"%Y"))
year.end.i<-as.numeric(format(end.i,"%Y"))
ID.i<-bb[i,'uniqueID']
doy.i<-as.numeric(format(start.i,"%j"))
doy.end.i<-as.numeric(format(end.i,"%j"))
clim.i<-subset(climdat, uniqueID==ID.i)
#clim.i$Tmean
if(dim(clim.i)[1]==0){#Ailene added; if no climate data for any years, avg_bbtemp is NA
bb$avg_bbtemp[i]<-NA
missingclim<-c(missingclim,i)
}
else if (length(unique(clim.i$year==year.end.i & clim.i$doy==doy.end.i))==1 & unique(clim.i$year==year.end.i & clim.i$doy==doy.end.i)==FALSE){
bb$avg_bbtemp[i]<-NA
}#Ailene added; if no climate data for one of required years, avg_bbtemp is NA
else if(!is.na(year.end.i) & dim(clim.i[which(clim.i$year==year.i & clim.i$doy==doy.i),])[1]!=0){
print(i)
bb$avg_bbtemp[i]<-mean(clim.i[which(clim.i$year==year.i & clim.i$doy==doy.i):
which(clim.i$year==year.end.i & clim.i$doy==doy.end.i),"Tmean"],na.rm=TRUE)
#clim.i<-subset(clim.i,year==year.i | year==year.end.i)
}
}
## checking missing values
#length(missingclim)
#bb[which(!uniquevalsbb%in%uniquevalsd),c("datasetID","End_year","bbdate","avg_bbtemp")]
## this data is not appended to d, but it is not a problem given that it is all NAs belonging to biasi12
## saving results to output - d
# generate indexes
uniquevalsd<-apply(d,1,paste,collapse="")
uniquevalsbb<-apply(bb[which(names(bb)%in%names(d))],1,paste,collapse="")
indexbb<-which(uniquevalsbb%in%uniquevalsd)
indexd<-which(uniquevalsd%in%uniquevalsbb)
# append average ambient forcing temperature to ospree dataset d
d$avg_bbtemp<-NA
d[indexd,"avg_bbtemp"]<-bb$avg_bbtemp[indexbb]
# note that only 2K rows have entires in avg_bbtemp and all have forcetemp
if(FALSE){
haveavgtemp <- subset(d, is.na(avg_bbtemp)==FALSE)
subset(haveavgtemp, is.na(forcetemp)==TRUE)
}
# but here's what we need
unique(d$forcetemp)
ambientforcetemp <- subset(d, forcetemp=="ambient"|forcetemp=="ambient + .7"|
forcetemp=="ambient + 4.9")
goober<-d[is.na(d$forcetemp),]
View(goober)
goober<-d[(d$forcetemp==""),]
View(goober)
goo<-d[(d$forcetemp=="ambient")]
goo<-d[(d$forcetemp=="ambient"),]
View(goo)
rm(list=ls())
options(stringsAsFactors = FALSE)
# Set working directory:
if(length(grep("Lizzie", getwd())>0)) { setwd("~/Documents/git/projects/treegarden/budreview/ospree/analyses")
} else if
(length(grep("Ignacio", getwd()))>0) { setwd("~/GitHub/ospree/analyses")
} else if
(length(grep("ailene", getwd()))>0) {setwd("/Users/aileneettinger/git/ospree/analyses")
} else
setwd("~/Documents/git/ospree/analyses")
# Load libraries
library(dplyr)
library(tidyr)
library(geosphere)
library(lubridate)
# 1. Get the data (that has already been cleaned for respvar and chilling)
d <- read.csv("output/ospree_clean_withchill.csv") # 29 May 2018: 12693
# 2. Need to deal with thermal time to days
source("bb_analysis/cleaning/clean_thermaltimetodays.R") # 29 May 2018: 12693
# 3. Clean phenstage to get a little more data (a little, but still!).
source("bb_analysis/cleaning/clean_respvarmore.R") # 29 May 2018: 12152
# 4. Select out the highest percentage of budburst only, and remove studies that contain duplicate data in two forms
source("bb_analysis/cleaning/multiresp.R") # as of 16 July 2017, deletes ~2400 rows (same in May 2018) 9717 rows
# 5. Clean ambient forcing
# 5a. Clean up entries where we can estimate the forcing from the paper (e.g., ramped temps or they give monthly temps)
source("bb_analysis/cleaning/clean_ambientforcing.R")
# 5b. Check date of daily climate files used in step 5c-
#if they are too old for your taste,run pulldailyclim.R and bb_daily_dataprep.R scripts (these take a while)
source("bb_analysis/cleaning/clean_checkdateofclimatedata.R") # As of 29 May 2018: 9717 rows
# 5c. Clean ambient forcing data using daily climate data
source("bb_analysis/cleaning/clean_ambientforcingfromdailyclimate.R") # still 9717 rows
# 6. Clean/convert percentBB to days, using a specified target bud-burst level (i.e. 90%)
# ... with an allowable buffer (i.e., 55%)
source("bb_analysis/cleaning/clean_bbperctodays.R") # As of 8 June 2018: 7372 rows
# 7. Clean duplicate responses across treatments/categories)
source("bb_analysis/cleaning/clean_moreduplicates.R") # As of 8 June 2018, deletes 2 rows (7370).
# 8. Clean photoperiod entries to try to get as much data as possible
source("bb_analysis/cleaning/clean_photoperiod.R")
install.packages("geosphere")
rm(list=ls())
options(stringsAsFactors = FALSE)
# Set working directory:
if(length(grep("Lizzie", getwd())>0)) { setwd("~/Documents/git/projects/treegarden/budreview/ospree/analyses")
} else if
(length(grep("Ignacio", getwd()))>0) { setwd("~/GitHub/ospree/analyses")
} else if
(length(grep("ailene", getwd()))>0) {setwd("/Users/aileneettinger/git/ospree/analyses")
} else
setwd("~/Documents/git/ospree/analyses")
# Load libraries
library(dplyr)
library(tidyr)
library(geosphere)
library(lubridate)
# 1. Get the data (that has already been cleaned for respvar and chilling)
d <- read.csv("output/ospree_clean_withchill.csv") # 29 May 2018: 12693
# 2. Need to deal with thermal time to days
source("bb_analysis/cleaning/clean_thermaltimetodays.R") # 29 May 2018: 12693
# 3. Clean phenstage to get a little more data (a little, but still!).
source("bb_analysis/cleaning/clean_respvarmore.R") # 29 May 2018: 12152
# 4. Select out the highest percentage of budburst only, and remove studies that contain duplicate data in two forms
source("bb_analysis/cleaning/multiresp.R") # as of 16 July 2017, deletes ~2400 rows (same in May 2018) 9717 rows
# 5. Clean ambient forcing
# 5a. Clean up entries where we can estimate the forcing from the paper (e.g., ramped temps or they give monthly temps)
source("bb_analysis/cleaning/clean_ambientforcing.R")
# 5b. Check date of daily climate files used in step 5c-
#if they are too old for your taste,run pulldailyclim.R and bb_daily_dataprep.R scripts (these take a while)
source("bb_analysis/cleaning/clean_checkdateofclimatedata.R") # As of 29 May 2018: 9717 rows
# 5c. Clean ambient forcing data using daily climate data
source("bb_analysis/cleaning/clean_ambientforcingfromdailyclimate.R") # still 9717 rows
# 6. Clean/convert percentBB to days, using a specified target bud-burst level (i.e. 90%)
# ... with an allowable buffer (i.e., 55%)
source("bb_analysis/cleaning/clean_bbperctodays.R") # As of 8 June 2018: 7372 rows
# 7. Clean duplicate responses across treatments/categories)
source("bb_analysis/cleaning/clean_moreduplicates.R") # As of 8 June 2018, deletes 2 rows (7370).
# 8. Clean photoperiod entries to try to get as much data as possible
source("bb_analysis/cleaning/clean_photoperiod.R")
table(d$force_type)
unique(d$forcetemp)
# 9. Write out the final file!
write.csv(d, "output/ospree_clean_withchill_BB.csv", row.names=FALSE) ## As of 8 June 2018: 7370 rows  (as of 29 May 2018: 7430)
# housekeeping
rm(list=ls()) # remove everything currently held in the R memory
options(stringsAsFactors=FALSE)
require(rstan)
require(brms)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
bb<-read.csv("~/Documents/git/regionalrisk/analyses/output/fs_space_new.csv", header=TRUE)
bb<-read.csv("~/Documents/git/regionalrisk/analyses/output/fs_space_new.csv", header=TRUE)
#bb<-read.csv("~/Documents/git/regionalrisk/analyses/output/fs_space_new.csv", header=TRUE)
bb<-subset(bb, select=c("species", "lat", "elev", "year", "mst", "cc", "fs.count", "nao",
"distkm", "eigen"))
bb$fs<-ifelse(bb$fs.count>0, 1, 0)
bb$nao.z <- (bb$nao-mean(bb$nao,na.rm=TRUE))/(2*sd(bb$nao,na.rm=TRUE))
bb$mat.z <- (bb$mst-mean(bb$mst,na.rm=TRUE))/(2*sd(bb$mst,na.rm=TRUE))
bb$cc.z <- (bb$cc-mean(bb$cc,na.rm=TRUE))/(2*sd(bb$cc,na.rm=TRUE))
bb$elev.z <- (bb$elev-mean(bb$elev,na.rm=TRUE))/(2*sd(bb$elev,na.rm=TRUE))
bb$lat.z <- (bb$lat-mean(bb$lat,na.rm=TRUE))/(2*sd(bb$lat,na.rm=TRUE))
bb$dist.z <-(bb$distkm-mean(bb$distkm,na.rm=TRUE))/(2*sd(bb$distkm,na.rm=TRUE))
bb$space.z <-(bb$eigen-mean(bb$eigen,na.rm=TRUE))/(2*sd(bb$eigen,na.rm=TRUE))
bb<-bb[sample(nrow(bb), 1000), ]
negbinom<-brm(fs ~ nao.z + mat.z + dist.z + space.z + elev.z +
cc.z + species + nao.z:species +
mat.z:species + dist.z:species + space.z:species + elev.z:species + cc.z:species +
nao.z:cc.z + mat.z:cc.z + dist.z:cc.z + space.z:cc.z + elev.z:cc.z, data=bb, chains=2,
family=negbinomial(), cores=2, iter = 4500, warmup=2500)
rm(list=ls())
options(stringsAsFactors = FALSE)
## Load Libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(rstanarm)
library(brms)
# Set Working Directory
setwd("~/Documents/git/treespotters/analysis")
## Data!
d<-read.csv("output/tree_rf_data.csv", header=TRUE)
View(d)
id<-read.csv("input/IDinfo.csv", header=TRUE)
colnames(id)
## ID info to find provenance
id<-subset(id, select=c("Individual_ID", "Plant_Nickname"))
id<-id[!duplicated(id),]
View(id)
write.csv(id, file="~/output/provenanceinfo.csv", row.names = FALSE)
write.csv(id, file="output/provenanceinfo.csv", row.names = FALSE)
